{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-learn - prediktívne modelovanie pomocou algoritmu k-najbližších susedov\n",
    "\n",
    "Cieľom príkladov v tejto lekcii je demonštrovať vytvorenie klasifikačného modelu k najbližších susedov na databáze Titanic. Ako cieľový atribút zvolíme `survived` a vytvorený klasikifačný model bude schopný na základe údajov o cestujúcich predikovať, či daný cestujúci prežil potopenie lode alebo nie. \n",
    "\n",
    "Cieľom posledného cvičenia bolo oboznámiť sa so základným postupom práce s knižnicou Scikit-learn. Ako ukážkový klasifikátor bol použitý algoritmus k najbližších susedov. V ukážkovej úlohe (aj na domácej úlohe) sme pracovali s datasetmi, ktoré obsahovali iba numerické atribúty a dáta sme nijak pred aplikovaním modelovania nepredspracovali. \n",
    "\n",
    "V rámci tohoto cvičenia si na úlohe predikcie atribútu `survived` datasetu Titanic ukážeme podrobnejšie prácu s k-NN. To bude okrem nastavenia rôznych parametrov algoritmu zahŕňať aj to, ako je nutné dáta pred aplikáciou kNN predspracovať a akými rôznymi spôsobmi je možné model kvalitatívne vyhodnotiť. \n",
    "\n",
    "Najprv teda naimportujeme všetky potrebné knižnice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz načítajte do dátového rámca `titanic` predspracované dáta z datasetu Titanic, z cvičenia č. 7. Nachádzajú sa v súbore `../data/titanic-processed.csv`.\n",
    " \n",
    "Vypíšte pomocou funkcie `head()` prvých 5 príkladov aby sme videli, aké atribúty máme popísané dáta v datasete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Titanic obsahuje okrem numerických aj kategorické atribúty. Takéto atribúty model k-NN nie je schopný spracovať. Pre použitie modelu k-najbližších susedov preto budeme musieť najprv vytvorené dáta vhodne transformovať. \n",
    "\n",
    "Okrem toho z datasetu môžeme odstrániť niektoré atribúty. Číslo lístka zrejme nebude mať výrazný vplyv na klasifikáciu, tak môžeme atribút `ticket` odstrániť. Atribút `title` môžeme odstrániť tiež, keďže budeme používať atribút `title_short`, ktorý vznikol jeho transformovaním. Odstránime aj atribúty `deck` a `cabin`, keďže obsahujú obrovské množstvo chýbajúcich hodnôt, ktoré nemáme ako nahradiť. \n",
    "\n",
    "Na uvedené transformácie použite funkciu `drop` nad dátovým rámcom `titanic`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformácia atribútov\n",
    "\n",
    "V nasledujúcich krokoch si ukážeme, ako môžeme atribúty v nevyhovujúcej forme pretransformovať. \n",
    "\n",
    "Nasledujúce atribúty obsahujú ako hodnoty reťazce a nemôžu byť v takejto podobe použité pri modelovaní k-NN:\n",
    "* `sex`\n",
    "* `embarked`\n",
    "* `has_family`\n",
    "* `fare_ordinal`\n",
    "* `title_short`\n",
    "* `age_ordinal`\n",
    "\n",
    "#### Transformácia binárnych (kategorických) atribútov na nominálne pomocou `LabelEncoder`\n",
    "\n",
    "Atribúty `sex` a `has_family` sú atribúty nadobúdajúce 2 hodnoty. Môžeme teda použiť jednoduchú transformáciu, ktorá ich hodnoty nahradí celým číslom. Na takúto operáciu môžeme použiť `LabelEncoder` z knižnice Scikit-learn. Ten pomocou funkcie `fit_transform()` pre atribút zadaný ako parameter nahradí všetky rôzne hodnoty indexom.  \n",
    "\n",
    "Rovnako by sme ale mohli použiť transformáciu pomocou dátových rámcov a funkcie `map()`. V zakomentovanej časti je kód, ktorý realizuje identickú operáciu pomocou `map()` funkcie ako použitím Label Encoderu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder # najprv importujeme potrebné funkcie\n",
    "\n",
    "titanic['sex'] = LabelEncoder().fit_transform(titanic['sex']) # vytvoríme LabelEncoder, použijeme ho na stĺpec `sex`, výsledok zapíšeme do titanic[`sex`]\n",
    "titanic['has_family'] = LabelEncoder().fit_transform(titanic['has_family']) # vytvoríme LabelEncoder a aplikujeme ho na stĺpec `has_family`, výsledok zapíšeme do titanic[`has_family`]\n",
    "\n",
    "## rovnaká transformácia pomocou funkcie map()\n",
    "# titanic['sex'] = titanic['sex'].map({\"male\": 0, \"female\": 1})\n",
    "# titanic['has_family'] = titanic['has_family'].map({False: 0, True: 1})\n",
    "\n",
    "titanic.head() # vypíšeme prvých 5 záznamov z dátového rámca a overíme transformáciu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformácia numerických atribútov na kategorické pomocou spôsobu `One Hot Encoding`\n",
    "\n",
    "Nie všetky atribúty je vhodné transformovať jednoduchým enkodérom (priradením číselných hodnôt pre rôzne hodnoty kategorického atribútu). Pri kategorických atribútoch s viacerými ako 2 hodnotami tak \"nechtiac\" vytvárame ich poradie. Niektoré modely (aj vrátane k-NN) by potom takto transformovaný atribút mohlo brať ako ordinálny, hoci v pôvodnom atribúte pred transformáciou žiadne usporiadanie neexistovalo. Ak sa tomu chceme vyhnúť, môžeme použiť tzv. One Hot Encoding. Pri takejto transformácii sa pre každú hodnotu kategorického atribútu odvodí nový, binárny atribút, ktorý bude špecifikovať, či príklady danú hodnotu nadobúdajú alebo nie. \n",
    "\n",
    "Takéto zakódovanie môžeme v pythone realizovať aj pomocou funkcie `get_dummies()` dátového rámca Pandas. Jej parametrami sú dátový rámec, s ktorým pracujeme a zoznam stĺpcov, ktoré chceme transformovať.  \n",
    "\n",
    "V našom prípade takto transformujeme atribúty `embarked` a `title_short`, nakoľko v oboch prípadoch ide o kategorické atribúty, ktoré nemajú usporiadanie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = pd.get_dummies(titanic, columns=['embarked', 'title_short']) # funkcii get_dummies špecifikujeme, ktoré atribúty chceme zakódovať na binárne\n",
    "titanic.head() # vypíšeme prvých 5 záznamov a overíme transformáciu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformácia ordinálnych kategorických atribútov na numerické\n",
    "\n",
    "Po uvedených transformáciách nám stále zostali 2 atribúty, ktoré je potrebné transformovať na numerické. V oboch prípadoch sa jedná o ordinálne kategorické atribúty, teda atribúty s jasne definovaným usporiadaním. Pre takéto atribúty môžeme použiť zakódovanie ako v prípade transformácie atribútov `sex` alebo `has_family`, no vzhľadom na existujúce usporiadanie hodnôt musíme špecifikovať zakódovanie manuálne. \n",
    "\n",
    "V prípade atribútov `fare_ordinal` a `age_ordinal` teda nadefinujeme ako nahradíme pôvodné hodnoty indexami. V prípade atribútu `fare_ordinal` je usporiadanie jeho hodnôt v poradí `normal` < `more expensive` < `most expensive` a tak týmto hodnotám priradíme indexy 0, 1, resp. 2, čím sa zachová usporiadanie. Analogicky budeme postupovať v prípade atribútu `age_ordinal`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic['fare_ordinal'] = titanic['fare_ordinal'].map({\"normal\": 0, \"more expensive\": 1, \"most expensive\": 2}) # transformujeme atribút tare_ordinal\n",
    "titanic['age_ordinal'] = titanic['age_ordinal'].map({\"child\": 0, \"young\": 1, \"adult\": 2, \"old\": 3}) # transformujeme atribút age_ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelovanie\n",
    "\n",
    "Na takto predspracovanej množine už môžeme vyskúšať natrénovať klasifikačný model. Podobne ako v predchádzajúcom cvičení najprv rozdelíme dáta do matice príznakov a vektora hodnôt cieľového atribútu.\n",
    "Cieľovým atribútom v tejto úlohe je `survived` (vyjadruje, či daný pasažier nehodu prežil alebo nie). Cieľový atribút teda bude tvoriť vektor hodnôt `y` a zostávajúce stĺpce maticu príznakov `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic = titanic.drop('survived', axis=1) # vytvoríme maticu príznakov - použijeme všetky stĺpce okrem cieľového atribútu a uložíme do X_titanic\n",
    "y_titanic = titanic['survived'] # vytvoríme vektor hodnôt cieľového atribútu ako stĺpec 'survived'\n",
    "\n",
    "print(X_titanic.shape) # pre kontrolu môžeme vypísať rozmery matice hodnôt a vektora cieľového atribútu\n",
    "print(y_titanic.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz rozdelíme dáta do trénovacej a testovacej množiny. Podstatné je, aby sme všetko predspracovanie (transformácie atribútov atď.) robili pred týmto krokom resp. ak neskôr, musíme si dať pozor, aby sme rovnaké postupy aplikovali jak na trénovaciu, tak testovaciu množinu. Obe z množín musia byť v rovnakom formáte, aby bolo natrénovaný model možné na testovacej množine evaluovať. \n",
    "\n",
    "Na rozdelenie dát na trénovacie a testovacie použijeme funkciu `train_test_split()`, tesovacia množina bude v pomere 30/70 k trénovacej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split # importujeme funkciu train_test_split()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_titanic, y_titanic, test_size=0.3, random_state=1) # rozdelíme dataset do trénovacej a testovacej časti, tak že testovacia bude 30% z celkového datasetu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vyhodnotenie pomocou metrík `accuracy`, `precision`, `recall`.\n",
    "\n",
    "Ďalej natrénujeme model k-NN s defaultne nastavenými parametrami. Model natrénujeme na trénovacej množine (`X_train` a `y_train`) a pomocou funkcie `predict()` vyhodnotíme jeho kvalitu na testovacej množine a vypíšeme jeho presnosť (accuracy) a tentoraz aj metriky precision a recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier # Importovanie triedy zodpovedajúcej modelu, ktorý budeme trénovať\n",
    "\n",
    "model = KNeighborsClassifier()                     # Natrénovanie modelu kNN  \n",
    "model.fit(X_train, y_train)                          # Trénovanie modelu na trénovacej množine \n",
    "y_model = model.predict(X_test)   \n",
    "\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score\n",
    "\n",
    "print(f\"Presnosť (accuracy) modelu: {accuracy_score(y_test, y_model)}\")\n",
    "print(f\"Presnosť (precision) modelu: {precision_score(y_test, y_model)}\")\n",
    "print(f\"Návratnosť (recall) modelu: {recall_score(y_test, y_model)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pomocou funkcie `confusion_matrix()` sa môžeme pozrieť, ako klasifikátor klasifikoval jednotlivé triedy a kde dochádzalo k najväčšej chybe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_model)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vyhodnotenie modelov pomocou ROC krivky\n",
    "\n",
    "ROC krivku môžeme pomocou Scikit-learn vypočítať funkciou `roc_curve()`. Jej vstupnými parametrami sú:\n",
    "* - vektor hodnôt cieľového atribútu testovacej množiny\n",
    "* - vektor modelom predikovaných hodnôt cieľového atribútu\n",
    "* - parameter `pos_label` - indikuje pozitívnu hodnotu\n",
    "\n",
    "Výstupom funkcie sú `tpr`, `fpr` a `threshold`, ktoré predstavujú hodnoty relatívna početnosť skutočne pozitívních príkladov (True Positive Rate) a relatívna početnosť falošne pozitívnych prípadov (False Positive Rate) a hodnoty prahu.\n",
    "Funkcia `auc()` potom vypočíta AUC hodnotu. \n",
    "Samotnú ROC krivku potom môžeme vykresliť pomocou matplotlib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc # z Scikit learn importujeme funkcie pre výpočet ROC krivky a AUC koeficientu\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_model, pos_label=1) \n",
    "# pomocou funkcie roc_curve vypočítame:\n",
    "# fpr - false positive rate\n",
    "# tpr - true positive rate\n",
    "# thresholds\n",
    "\n",
    "roc_auc = auc(fpr, tpr) # výpočet AUC koeficientu\n",
    "\n",
    "# pomocou matplotlib vykreslíme ROC krivku\n",
    "plt.title('ROC Krivka') # definujeme názov obrázku\n",
    "\n",
    "# vykreslíme ROC krivku, farbou \"navy\" (môžeme použiť ako parameter názov farby), vypíšeme do legendy AUC koeficient\n",
    "plt.plot(fpr, tpr, color='green', label = 'ROC krivka modelu (AUC = %0.2f)' % roc_auc) \n",
    "\n",
    "plt.legend(loc = 'lower right') # nastavíme vykreslenie legendy vpravo dole\n",
    "plt.plot([0, 1], [0, 1],linestyle='--', color='red') # vykreslíme červenou (r) prerušovanou farbou diagonálu\n",
    "plt.xlim([0, 1]) # os x bude nadobúdať hodnoty od 0 do 1\n",
    "plt.ylim([0, 1]) # os y bude nadobúdať hodnoty od 0 do 1\n",
    "plt.ylabel('True Positive Rate') # jednotlivé osi otitulkujeme\n",
    "plt.xlabel('False Positive Rate') # jednotlivé osi otitulkujeme\n",
    "plt.show() # zobrazíme obrázok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keďže je klasifikátor k-NN náchylný na mierky numerických atribútov, je vhodné zabezpečiť, aby jednotlivé atribúty mali rovnaký vplyv pri výpočte, resp. aby vďaka rôznym škálam jednotlivých atribútov nedochádzalo k potlačeniu niektorých z nich, resp. naopak aby niektoré neboli výraznejšie. \n",
    "\n",
    "Toto je možné dosiahnuť normalizáciou numerických atribútov, ktorá číselný atribút v určitom rozsahu normalizuje na definovaný interval. Je dobré použiť jednotný typ normalizácie pre všetky atribúty, ktoré tak budú nadobúdať hodnoty rovnakom rozsahu. \n",
    "\n",
    "### Normalizácia atribútov\n",
    "\n",
    "Pri preskúmaní transformovaného datasetu zistíme, že 2 atribúty `fare` a `age` nadpbúdajú výrazne odlišnejšie hodnoty od ostatných atribútov.\n",
    "\n",
    "Normzalizáciu môžeme použiť pomocou transformácie `MinMaxScaler`. Tú možeme v tomto prípade aplikovať na vybrané atribúty, alebo na celý dátový rámec. V našom prípade aplikujeme na všetky atribúty. Normalizované dáta uložíme do dátového rámca `normData`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler # importujeme knižnice potrebné pre MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler() #inicializujeme transformáciu\n",
    "normData = pd.DataFrame(scaler.fit_transform(titanic), index=titanic.index, columns=titanic.columns) #použijeme transformátor na dátový rámec titanic, výsledok (pole) transforujeme naspať do dátového rámca v rovnakej štruktúre ako pôvodný rámec\n",
    "normData.head() # vypíšeme prvých 5 záznamov pre kontrolu\n",
    "\n",
    "## ak chceme transformovať iba zvolené atribúty, urobíme to takto:\n",
    "# titanic['fare'] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(titanic['fare'])), columns=['fare']) \n",
    "# titanic['age'] = pd.DataFrame(scaler.fit_transform(pd.DataFrame(titanic['age'])), columns=['age'])\n",
    "# normData = titanic \n",
    "# normData.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Úloha 11.1\n",
    "\n",
    "Trasnformovaný dataset rozdeľte rovnako ako netransformovaný do trénovacej a testovacej množiny (testovacia o veľkosti 30% celkovej). Na transformovanom datasete natrénujte model k-NN a porovnajte jeho presnosť s modelom na netransformovaných dátach. Použite na porovnanie presnosť, návratnosť a `confusion_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Úloha 11.2\n",
    "\n",
    "Vykreslite do jedného grafu súčasne ROC krivky dvoch (alebo viacerých) modelov (napr. dvoch k-NN modelov s rôznymi hodnotami parametra `k`) a porovnajte ich. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Úloha 11.3\n",
    "\n",
    "Skúste teraz model na normalizovaných dátach vyladiť nastavením jeho parametrov. Ako sme si spomínali, pri k-NN algoritme môžeme nastavovať niekoľko parametrov, napr. hodnotu `k`, pre klasifikátor `KNeighborsClassifier` je to parameter:\n",
    "\n",
    "* `n_neighbors` - zodpovedá hodnote `k`, počet najbližších susedov, podľa ktorých budeme neoznačené príklady klasifikovať\n",
    "\n",
    "Na konkrétnu hodnotu ho nastavíte pr inicializácii modelu takto: `model = KNeighborsClassifier(n_neighbors=3)`\n",
    "\n",
    "Skúste postupovať podľa inštrukcií z cvičenia č. 10, tzn. začať s najjednodušším modelom (parameter `k`=1), ktorý budete zvyšovať, až kým sa kvalita modelu neprestane zvyšovať. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Úloha 11.4\n",
    "\n",
    "Natrénujte k-NN model na datasete Titanic tak, že na jeho validáciu použijete krížovú validáciu na trénovacej množine. Vyskúšajte pri trénovaní modelov aj vplyv iných parametrov na výslednú kvalitu modelu:\n",
    "\n",
    "* `weights` - váhovanie, hodnota `uniform` špecifikuje rovnakú váhu hlasu každého z k najbližších susedov, hodnota `distance` váhuje ich vplyv podľa vzdialenosti\n",
    "* `metric`- špecifikuje používanú metriku, hodnoty napr. `euclidean`, `manhattan`.\n",
    "\n",
    "Tieto nastavíte napr. takto: `model = KNeighborsClassifier(n_neighbors=10, weights='uniform',metric='manhattan')`. V rámci krížovej validácie spočítajte priemerné `score` modelov. \n",
    "\n",
    "\n",
    "Skúste tak nájsť najlepšiu kombináciu parametrov a najlepší z modelov potom otestujte na testovacej množine. Na testovacej množine vypočítajte metriky `accuracy`, `precision`, `recall` a vypíšte `confusion matrix`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
